{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "sklearn.set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mammography Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammography = fetch_openml(data_id=310)\n",
    "X, y = mammography.data, mammography.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y == '1').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base models\n",
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_log_reg = LogisticRegression(random_state=42)\n",
    "log_reg_scores = cross_validate(base_log_reg,\n",
    "                                X_train, y_train, scoring=['roc_auc', 'average_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_base_auc = log_reg_scores['test_roc_auc'].mean()\n",
    "log_reg_base_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_base_ap = log_reg_scores['test_average_precision'].mean()\n",
    "log_reg_base_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rf = RandomForestClassifier(random_state=42)\n",
    "rf_scores = cross_validate(base_rf, X_train, y_train, scoring=['roc_auc', 'average_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base_auc = rf_scores['test_roc_auc'].mean()\n",
    "rf_base_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base_ap = rf_scores['test_average_precision'].mean()\n",
    "rf_base_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance-learn sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler = RandomUnderSampler(replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample, y_train_subsample = under_sampler.fit_sample(\n",
    "    X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train_subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler = RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample, y_train_subsample = over_sampler.fit_sample(\n",
    "    X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train_subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines with imblean\n",
    "\n",
    "### Linear model with under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_log_reg = make_imb_pipeline(\n",
    "    RandomUnderSampler(), LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_log_reg_scores = cross_validate(\n",
    "    under_log_reg, X_train, y_train, cv=10,\n",
    "    scoring=['roc_auc', 'average_precision']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_base_auc, log_reg_base_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_log_reg_auc = under_log_reg_scores['test_roc_auc'].mean()\n",
    "under_log_reg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_log_reg_ap = under_log_reg_scores['test_average_precision'].mean()\n",
    "under_log_reg_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_rf = make_imb_pipeline(\n",
    "    RandomUnderSampler(), RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_rf_reg_scores = cross_validate(\n",
    "    under_rf, X_train, y_train, cv=10,\n",
    "    scoring=['roc_auc', 'average_precision']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base_auc, rf_base_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_rf_auc = under_rf_reg_scores['test_roc_auc'].mean()\n",
    "under_rf_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_rf_ap = under_rf_reg_scores['test_average_precision'].mean()\n",
    "under_rf_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model with over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log_reg = make_imb_pipeline(\n",
    "    RandomOverSampler(), LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log_reg_scores = cross_validate(\n",
    "    over_log_reg, X_train, y_train, cv=10,\n",
    "    scoring=['roc_auc', 'average_precision']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_base_auc, log_reg_base_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log_reg_auc = over_log_reg_scores['test_roc_auc'].mean()\n",
    "over_log_reg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_log_reg_ap = over_log_reg_scores['test_average_precision'].mean()\n",
    "over_log_reg_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Use `make_imb_pipeline` with `RandomOverSampler` to create a pipline with random forset called `over_rf`.\n",
    "1. Use `cross_validate` to compute `over_rf_auc` and `over_rf_ap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02-ex01-solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting curves for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_log_reg.fit(X_train, y_train)\n",
    "under_log_reg.fit(X_train, y_train)\n",
    "over_log_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "plot_roc_curve(base_log_reg, X_test, y_test, ax=ax1, name=\"original\")\n",
    "plot_roc_curve(under_log_reg, X_test, y_test, ax=ax1, name=\"undersampling\")\n",
    "plot_roc_curve(over_log_reg, X_test, y_test, ax=ax1, name=\"oversampling\")\n",
    "\n",
    "plot_precision_recall_curve(base_log_reg, X_test, y_test, ax=ax2, name=\"original\")\n",
    "plot_precision_recall_curve(under_log_reg, X_test, y_test, ax=ax2, name=\"undersampling\")\n",
    "plot_precision_recall_curve(over_log_reg, X_test, y_test, ax=ax2, name=\"oversampling\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Train the three random forest models, `base_rf`, `under_rf`, `over_rf`.\n",
    "1. Plot the roc and precision recall for the three random forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02-ex02-solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "class_weight_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "plot_roc_curve(log_reg, X_test, y_test, ax=ax1, name=\"original\")\n",
    "plot_roc_curve(class_weight_log_reg, X_test, y_test, ax=ax1, name=\"class-weighted\")\n",
    "\n",
    "plot_precision_recall_curve(log_reg, X_test, y_test, ax=ax2, name=\"original\")\n",
    "plot_precision_recall_curve(class_weight_log_reg, X_test, y_test, ax=ax2, name=\"class-weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with class weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "class_weight_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "plot_roc_curve(base_rf, X_test, y_test, ax=ax1, name=\"original\")\n",
    "plot_roc_curve(class_weight_rf, X_test, y_test, ax=ax1, name=\"class-weighted\")\n",
    "\n",
    "plot_precision_recall_curve(base_rf, X_test, y_test, ax=ax2, name=\"original\")\n",
    "plot_precision_recall_curve(class_weight_rf, X_test, y_test, ax=ax2, name=\"class-weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_rf = BalancedRandomForestClassifier(random_state=0)\n",
    "balanced_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "plot_roc_curve(base_rf, X_test, y_test, ax=ax1, name=\"original\")\n",
    "plot_roc_curve(under_rf, X_test, y_test, ax=ax1, name=\"undersampling\")\n",
    "plot_roc_curve(over_rf, X_test, y_test, ax=ax1, name=\"oversampling\")\n",
    "plot_roc_curve(balanced_rf, X_test, y_test, ax=ax1, name=\"balanced bagging\")\n",
    "\n",
    "plot_precision_recall_curve(base_rf, X_test, y_test, ax=ax2, name=\"original\")\n",
    "plot_precision_recall_curve(under_rf, X_test, y_test, ax=ax2, name=\"undersampling\")\n",
    "plot_precision_recall_curve(over_rf, X_test, y_test, ax=ax2, name=\"oversampling\");\n",
    "plot_precision_recall_curve(balanced_rf, X_test, y_test, ax=ax2, name=\"balanced bagging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, under_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, over_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, base_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, balanced_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sorting = np.argsort(y_train)\n",
    "\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].scatter(X_train[sorting, 3], X_train[sorting, 4], c=plt.cm.tab10(y_train[sorting]), alpha=.3, s=2)\n",
    "\n",
    "axes[1].set_title(\"SMOTE\")\n",
    "axes[1].scatter(X_train_smote[:, 3], X_train_smote[:, 4], c=plt.cm.tab10(y_train_smote), alpha=.1, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_base_auc, log_reg_base_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_log_reg = make_imb_pipeline(\n",
    "    SMOTE(), LogisticRegression(random_state=42))\n",
    "\n",
    "smote_log_reg_scores = cross_validate(smote_log_reg, X_train, y_train, cv=10,\n",
    "                        scoring=('roc_auc', 'average_precision'))\n",
    "smote_log_reg_auc = smote_log_reg_scores['test_roc_auc'].mean()\n",
    "smote_log_reg_ap = smote_log_reg_scores['test_average_precision'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_log_reg_auc, smote_log_reg_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_rf = make_imb_pipeline(SMOTE(), RandomForestClassifier(random_state=42))\n",
    "smote_rf_scores = cross_validate(smote_rf, X_train, y_train, cv=10,\n",
    "                        scoring=('roc_auc', 'average_precision'))\n",
    "smote_rf_auc = smote_rf_scores['test_roc_auc'].mean()\n",
    "smote_rf_ap = smote_rf_scores['test_average_precision'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_rf_auc, smote_rf_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all the version of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "plot_roc_curve(base_rf, X_test, y_test, ax=ax1, name=\"original\")\n",
    "plot_roc_curve(under_rf, X_test, y_test, ax=ax1, name=\"undersampling\")\n",
    "plot_roc_curve(over_rf, X_test, y_test, ax=ax1, name=\"oversampling\")\n",
    "plot_roc_curve(balanced_rf, X_test, y_test, ax=ax1, name=\"balanced bagging\")\n",
    "plot_roc_curve(smote_rf, X_test, y_test, ax=ax1, name=\"smote\")\n",
    "\n",
    "plot_precision_recall_curve(base_rf, X_test, y_test, ax=ax2, name=\"original\")\n",
    "plot_precision_recall_curve(under_rf, X_test, y_test, ax=ax2, name=\"undersampling\")\n",
    "plot_precision_recall_curve(over_rf, X_test, y_test, ax=ax2, name=\"oversampling\");\n",
    "plot_precision_recall_curve(balanced_rf, X_test, y_test, ax=ax2, name=\"balanced bagging\")\n",
    "plot_precision_recall_curve(smote_rf, X_test, y_test, ax=ax2, name=\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "1. Train a `HistGradientBoostingClassifer` on the training set.\n",
    "\n",
    "```py\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifer\n",
    "```\n",
    "\n",
    "1. Construct a pipline with `SMOTE` and `HistGradientBoostingClassifer` fit it on the training set.\n",
    "1. Plot the ROC and PR curves between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02-ex03-solutions.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop-advanced",
   "language": "python",
   "name": "conda-env-ml-workshop-advanced-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
